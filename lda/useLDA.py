import os
import gensim
import pandas as pd
import ast # ç”¨æ–¼å®‰å…¨è½‰æ›å­—ä¸²åˆ—è¡¨
import numpy as np
from tqdm import tqdm # ç”¨æ–¼é¡¯ç¤ºè™•ç†é€²åº¦

# ====================================================================
# 1. æ¨¡å‹è¼‰å…¥å’Œé…ç½®
# ====================================================================

# é…ç½®ï¼šè«‹ç¢ºèªé€™äº›è·¯å¾‘å’Œåƒæ•¸èˆ‡æ‚¨è¨“ç·´æ™‚å®Œå…¨ä¸€è‡´
BASE_DIR = 'C:\\Users\\zac\\PyCharmMiscProject'  # ä½¿ç”¨é›™åæ–œç·š
MODEL_DIR = os.path.join(BASE_DIR, "lda_model_assets")
NUM_TOPICS = 10

lda_model_path = os.path.join(MODEL_DIR, f"lda_kpop_{NUM_TOPICS}_topics.model")
dictionary_path = os.path.join(MODEL_DIR, f"lda_kpop_{NUM_TOPICS}_dictionary.dict")

try:
    # è¼‰å…¥æ¨¡å‹å’Œè©å…¸
    loaded_lda_model = gensim.models.LdaModel.load(lda_model_path)
    loaded_dictionary = gensim.corpora.Dictionary.load(dictionary_path)
    print(f"âœ… æˆåŠŸè¼‰å…¥ {NUM_TOPICS} å€‹ä¸»é¡Œçš„ LDA æ¨¡å‹å’Œè©å…¸ã€‚")

except FileNotFoundError:
    # å¦‚æœè¼‰å…¥å¤±æ•—ï¼Œå‰‡é€€å‡ºç¨‹å¼
    print("ğŸš¨ è‡´å‘½éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æˆ–è©å…¸æª”æ¡ˆã€‚è«‹ç¢ºèª BASE_DIR è¨­å®šæ˜¯å¦æ­£ç¢ºã€‚")
    exit()


# ====================================================================
# 2. æ•¸æ“šè®€å–å’Œé è™•ç†
# ====================================================================

# å®šç¾©æ–°æ•¸æ“šæª”æ¡ˆè·¯å¾‘
NEW_DATA_FILE = 'data/new_LDA.csv' # ä½¿ç”¨åŸå§‹å­—ä¸²æˆ– os.path.join è™•ç† Windows è·¯å¾‘

df_new = pd.read_csv(NEW_DATA_FILE)

# å®šç¾©å®‰å…¨è½‰æ›å‡½æ•¸ (å¾æ‚¨åŸä¾†çš„ä»£ç¢¼è¤‡è£½)
def convert_str_to_list(list_str):
    try:
        return ast.literal_eval(list_str)
    except (ValueError, TypeError):
        return []

# æ‡‰ç”¨è½‰æ›
df_new['final_tokens_restored'] = df_new['final_tokens'].apply(convert_str_to_list)

# æº–å‚™æ–‡æª”åˆ—è¡¨ä¸¦ç§»é™¤ç©ºæ–‡æª”
documents_new = df_new['final_tokens_restored'].tolist()
documents_new_cleaned = [doc for doc in documents_new if doc]

# ç”±æ–¼æˆ‘å€‘åªå°éç©ºæ–‡æª”é€²è¡Œè™•ç†ï¼Œæˆ‘å€‘éœ€è¦ä¸€å€‹ç´¢å¼•ä¾†å°‡çµæœé‡æ–°æ˜ å°„å›åŸå§‹ df_new
non_empty_indices = [i for i, doc in enumerate(documents_new) if doc]

# å‰µå»º BoW èªæ–™åº«
corpus_new = [loaded_dictionary.doc2bow(doc) for doc in tqdm(documents_new_cleaned, desc="è½‰æ›ç‚º BoW æ ¼å¼")]

print(f"âœ… è®€å– {len(df_new)} ç­†æ•¸æ“šï¼Œå…¶ä¸­ {len(corpus_new)} ç­†æœ‰æ•ˆæ–‡æª”ç”¨æ–¼æ¨æ–·ã€‚")

# ====================================================================
# 3. ä¸»é¡Œæ¨æ–· (Inference)
# ====================================================================

# é‹è¡Œä¸»é¡Œæ¨æ–·
print("\né–‹å§‹é€²è¡Œä¸»é¡Œæ¨æ–·...")
doc_topics_inferred = [
    loaded_lda_model.get_document_topics(
        doc,
        minimum_probability=0.0
    )
    for doc in tqdm(corpus_new, desc="æ¨æ–·ä¸»é¡Œæ¦‚ç‡")
]


# ====================================================================
# 4. çµæœæ ¼å¼åŒ–å’Œåˆä½µ
# ====================================================================

# å°‡ (Topic_ID, Probability) åˆ—è¡¨è½‰æ›ç‚ºå›ºå®šé•·åº¦çš„æ¦‚ç‡å‘é‡ (å¾æ‚¨åŸä¾†çš„ä»£ç¢¼è¤‡è£½)
def format_topic_distribution(topic_list, num_topics):
    prob_vector = np.zeros(num_topics)
    for topic_id, prob in topic_list:
        if topic_id < num_topics:
            prob_vector[topic_id] = prob
    return prob_vector.tolist()

# æ‡‰ç”¨æ ¼å¼åŒ–å‡½æ•¸
topic_distributions = [format_topic_distribution(doc, NUM_TOPICS) for doc in doc_topics_inferred]

# å‰µå»ºæ–°çš„ DataFrame æ¬„ä½åç¨±
topic_cols = [f'Topic_{i + 1}_Prob' for i in range(NUM_TOPICS)]
df_topic_probs = pd.DataFrame(topic_distributions, columns=topic_cols)

# å‰µå»ºä¸€å€‹æ–°çš„å®Œæ•´ DataFrame ä¾†ä¿å­˜æ¨æ–·çµæœ
# é¦–å…ˆå»ºç«‹ä¸€å€‹ç©ºçš„ DataFrameï¼Œé•·åº¦èˆ‡åŸå§‹ df_new ç›¸åŒ
df_results = df_new.copy()

# åˆå§‹åŒ–ä¸»é¡Œæ¦‚ç‡æ¬„ä½ç‚º 0 (è™•ç†é‚£äº›ç©ºæ–‡æª”)
for col in topic_cols:
    df_results[col] = 0.0

# å°‡æ¨æ–·çš„æ¦‚ç‡å¡«å…¥å°æ‡‰çš„éç©ºè¡Œ
# df_topic_probs çš„è¡Œæ•¸ == documents_new_cleaned çš„è¡Œæ•¸
df_results.loc[non_empty_indices, topic_cols] = df_topic_probs.values


# 5. æ‰¾å‡ºä¸»å°ä¸»é¡Œ
df_results['Dominant_Topic_Prob'] = df_results[topic_cols].max(axis=1)
df_results['Dominant_Topic_index'] = df_results[topic_cols].idxmax(axis=1).str.replace('_Prob', '').str.replace('Topic_', '').astype(int)
df_results['Dominant_Topic'] = df_results['Dominant_Topic_index'].apply(lambda x: f'Topic_{x}')


# ====================================================================
# 5. è¼¸å‡ºçµæœ
# ====================================================================

output_file_name = 'data_new_LDA_with_topics.csv'
df_results.to_csv(output_file_name, index=False, encoding='utf-8-sig')

print("\n--- æ¨æ–·çµæœç¯„ä¾‹ (å‰ 5 ç­†) ---")
# å‡è¨­ä½ çš„åŸå§‹ data/new_LDA.csv æœ‰ 'title' æˆ– 'song' æ¬„ä½
display_cols = ['Dominant_Topic', 'Dominant_Topic_Prob'] + topic_cols
print(df_results.head()[display_cols])

print(f"\nâœ¨ æˆåŠŸå°‡ä¸»é¡Œçµæœè¼¸å‡ºåˆ°æª”æ¡ˆï¼š{output_file_name}")
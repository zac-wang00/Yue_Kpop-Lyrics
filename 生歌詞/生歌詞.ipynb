{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b01e1cba098403fba8ce8048d7d2edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62f2cc22f0bc4b5eb65ccae6ae299c41",
              "IPY_MODEL_95e1d65bf8994d07a0d55a2f5162e8d0",
              "IPY_MODEL_81fff1dc45374810a420db9909999f13"
            ],
            "layout": "IPY_MODEL_db3f351b963b44059506633b923ea260"
          }
        },
        "62f2cc22f0bc4b5eb65ccae6ae299c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff3448565604eb4b1bc25ed727a3732",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6c845788f2f146558cf1e2a38e25f325",
            "value": "Map:‚Äá100%"
          }
        },
        "95e1d65bf8994d07a0d55a2f5162e8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e6348a5c5bb4872a5f52898b6d361b7",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18084b46ad8f450c8d4d69bd95b830f4",
            "value": 20
          }
        },
        "81fff1dc45374810a420db9909999f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f229c550c02f42fdb1c0220d786308b0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_93d29c24f97f452b9253a41acff29fbc",
            "value": "‚Äá20/20‚Äá[00:00&lt;00:00,‚Äá238.91‚Äáexamples/s]"
          }
        },
        "db3f351b963b44059506633b923ea260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff3448565604eb4b1bc25ed727a3732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c845788f2f146558cf1e2a38e25f325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e6348a5c5bb4872a5f52898b6d361b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18084b46ad8f450c8d4d69bd95b830f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f229c550c02f42fdb1c0220d786308b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d29c24f97f452b9253a41acff29fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "707197cb7aff4ef0a1caddfca08b0f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3adba48c26524ea2b9696647ab725138",
              "IPY_MODEL_df3440cb7a044865a3e34d8d9baed274",
              "IPY_MODEL_96b225ac781344c890b9a44568d090e5"
            ],
            "layout": "IPY_MODEL_059f7b1a589941ab9564b10be59a3f14"
          }
        },
        "3adba48c26524ea2b9696647ab725138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3478529c85f44795a66e839d081f6d41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_89076e752a634187af20897452d37056",
            "value": "Map:‚Äá100%"
          }
        },
        "df3440cb7a044865a3e34d8d9baed274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77de6a7c6a23496e847e513da0e0562b",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00710ccab52a4153a3e39be39ed491d5",
            "value": 20
          }
        },
        "96b225ac781344c890b9a44568d090e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5797afeb81ba47c1ac4d797202a0e8cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ef21aff02dec4e16a68beb39c759a1dd",
            "value": "‚Äá20/20‚Äá[00:00&lt;00:00,‚Äá303.62‚Äáexamples/s]"
          }
        },
        "059f7b1a589941ab9564b10be59a3f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3478529c85f44795a66e839d081f6d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89076e752a634187af20897452d37056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77de6a7c6a23496e847e513da0e0562b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00710ccab52a4153a3e39be39ed491d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5797afeb81ba47c1ac4d797202a0e8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef21aff02dec4e16a68beb39c759a1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXaGPD8V320U",
        "outputId": "832d55cc-5087-452e-fa75-f1f6266e2006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Áí∞Â¢ÉË®≠ÁΩÆËàáÂÆâË£ù ---\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "‰ΩøÁî®Ë®≠ÂÇô: cuda\n"
          ]
        }
      ],
      "source": [
        "# ÈÄôÊòØÊÇ®ÊáâË©≤Âú® Google Colab ÊàñÊúâ GPU ÁöÑÁí∞Â¢É‰∏≠ÈÅãË°åÁöÑ‰ª£Á¢º\n",
        "\n",
        "# =================================================================\n",
        "# Ê≠•È©ü 1: Áí∞Â¢ÉË®≠ÁΩÆËàáÂÆâË£ù\n",
        "# =================================================================\n",
        "print(\"--- 1. Áí∞Â¢ÉË®≠ÁΩÆËàáÂÆâË£ù ---\")\n",
        "# ÂÆâË£ùÂøÖË¶ÅÁöÑÂáΩÂºèÂ∫´\n",
        "# Áî±ÊñºË¶ÅËôïÁêÜÈüìÊñáÔºåÂª∫Ë≠∞‰ΩøÁî®Â∞àÈñÄÁöÑÈüìÊñáÊ®°Âûã\n",
        "!pip install transformers pandas datasets accelerate -U\n",
        "!pip install sentencepiece # Â∞çÊñºÊüê‰∫õÈüìÊñáÊ®°ÂûãÂèØËÉΩÈúÄË¶Å\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "# Ê™¢Êü• CUDA (GPU) ÊòØÂê¶ÂèØÁî®\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"‰ΩøÁî®Ë®≠ÂÇô: {device}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "# ÂÅáÂÆöÂÖ∂‰ªñÂøÖË¶ÅÁöÑÂåØÂÖ• (transformers, etc.) ÈÉΩÂú®ÊÇ®ÁöÑÂÆåÊï¥Á®ãÂºèÁ¢º‰∏≠\n",
        "\n",
        "def clean_and_extract_year(date_str):\n",
        "    # (Êó•ÊúüÊ∏ÖÁêÜÂáΩÊï∏‰øùÊåÅ‰∏çËÆä)\n",
        "    if pd.isna(date_str) or date_str == '':\n",
        "        return None\n",
        "    try:\n",
        "        # ÂòóË©¶ËΩâÊèõÂÆåÊï¥ÁöÑ 'YYYY/MM/DD' Ê†ºÂºè\n",
        "        return pd.to_datetime(date_str, format='%Y/%m/%d').year\n",
        "    except:\n",
        "        pass\n",
        "    if isinstance(date_str, (int, float)):\n",
        "        date_str = str(int(date_str))\n",
        "\n",
        "    if isinstance(date_str, str) and date_str.isdigit() and len(date_str) == 4:\n",
        "        # ÈÄôÊòØÁ¥îÂπ¥‰ªΩÔºåÁõ¥Êé•ËøîÂõûÊï¥Êï∏Âπ¥‰ªΩ\n",
        "        return int(date_str)\n",
        "\n",
        "    return None\n",
        "\n",
        "print(\"--- 2. Êï∏ÊìöÊ∫ñÂÇôËàáÁØ©ÈÅ∏ (HOT 2010-2019) - ÊúÄÁµÇÂ≠óÂÖÉ‰øÆÊ≠£ ---\")\n",
        "try:\n",
        "    df = pd.read_csv(\"final_SM.csv\")\n",
        "\n",
        "    # üö® ‰øÆÊ≠£Ê≠•È©ü 1ÔºöÈáçÊñ∞ÂâµÂª∫ 'full_lyrics' Ê¨Ñ‰Ωç\n",
        "    original_lyrics_col = 'lyrics'\n",
        "\n",
        "# Áõ¥Êé•‰ΩøÁî®ÂéüÂßãÊ≠åË©û\n",
        "    df['full_lyrics'] = df[original_lyrics_col].fillna(\"\").astype(str)\n",
        "\n",
        "\n",
        "\n",
        "    # ‰øÆÊ≠£Ê≠•È©ü 2ÔºöÂü∑Ë°åÊó•ÊúüÊ∏ÖÊ¥óÂíåÂπ¥‰ªΩÊèêÂèñ\n",
        "    df['release_year'] = df['release_date'].apply(clean_and_extract_year)\n",
        "    df = df.dropna(subset=['release_year'])\n",
        "    df['release_year'] = df['release_year'].astype(int)\n",
        "\n",
        "    # üö® ‰øÆÊ≠£Ê≠•È©ü 3ÔºöÁ≤æÁ¢∫ÂåπÈÖçÊÇ®Á¢∫Ë™çÁöÑÂ≠óÂÖÉ Girls‚Äô Generation\n",
        "    # ÊàëÂÄëÂ∞á‰ΩøÁî®ÂÖ©Á®ÆÂ∏∏Ë¶ãÁöÑÂñÆÂºïËôüÊ†ºÂºè‰æÜÁ¢∫‰øùÂåπÈÖçÊàêÂäü\n",
        "\n",
        "    # Ë®≠ÁΩÆÁõÆÊ®ôÂúòÈ´îÂêçÁ®±Ôºö‰ΩøÁî®ÊÇ®Á¢∫Ë™çÁöÑÂè≥ÂñÆÂºïËôü\n",
        "    target_group_accurate = 'H.O.T'\n",
        "\n",
        "    # ‰ΩøÁî®ÂåÖÂê´Âà§Êñ∑ (Ê®°Á≥äÂåπÈÖç) ‰æÜÊáâÂ∞çÂêÑÁ®ÆÂêçÁ®±ËÆäÈ´î (Â¶Ç Girls' Generation (TTS) Á≠â)\n",
        "    is_artist = df['recording_artist_credit'].astype(str).str.contains(target_group_accurate, case=False, na=False)\n",
        "\n",
        "    # È°çÂ§ñÂà§Êñ∑ÔºöÁ¢∫‰øù‰πüËÉΩÂåπÈÖçÊ®ôÊ∫ñÊíáËôü '\n",
        "    target_group_fallback = \"H.O.T\"\n",
        "    is_artist_fallback = df['recording_artist_credit'].astype(str).str.contains(target_group_fallback, case=False, na=False)\n",
        "\n",
        "    # Âêà‰ΩµÂÖ©Á®ÆÂåπÈÖçÁµêÊûú\n",
        "    final_artist_match = is_artist | is_artist_fallback\n",
        "\n",
        "\n",
        "    target_df = df[\n",
        "        final_artist_match & # ‰ΩøÁî®ÂÑ™ÂåñÁöÑËóùË°ìÂÆ∂ÂåπÈÖçÈÇèËºØ\n",
        "        (df['release_year'] >= 2000) &\n",
        "        (df['release_year'] <= 2019)\n",
        "    ].copy()\n",
        "\n",
        "    # Ê™¢Êü•ÁµêÊûú\n",
        "    target_df = target_df[['full_lyrics']].dropna()\n",
        "\n",
        "    if target_df.empty:\n",
        "        print(f\"Ë≠¶Âëä: ÁØ©ÈÅ∏Ê¢ù‰ª∂Â§™Âö¥Ê†ºÊàñÊï∏Êìö‰∏çÁ¨¶„ÄÇÂú® '{target_group_accurate}' ({2010}-{2019}) Âπ¥ÈñìÊú™ÊâæÂà∞Ê≠åË©ûÊï∏Êìö„ÄÇ\")\n",
        "        print(\"Ë´ãÊ™¢Êü•Ôºö1. Êï∏Êìö‰∏≠ÊòØÂê¶ÈÇÑÊúâÂÖ∂‰ªñÂêçÁ®±ÊãºÂØ´Ôºü 2. ÊÇ®ÁöÑ 'release_year' Ê¨Ñ‰ΩçÊòØÂê¶Ê≠£Á¢∫ÊèêÂèñÂπ¥‰ªΩÔºü\")\n",
        "    else:\n",
        "        print(f\"‚úÖ ÁØ©ÈÅ∏Âá∫ {len(target_df)} Á≠ÜÁõÆÊ®ôÊ≠åË©ûÊï∏Êìö„ÄÇ\")\n",
        "        # ÁπºÁ∫å Dataset ËΩâÊèõ...\n",
        "        # lyrics_dataset = Dataset.from_pandas(target_df.reset_index(drop=True))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Ëá¥ÂëΩÈåØË™§: Êâæ‰∏çÂà∞ 'final_SM.csv' Ê™îÊ°à„ÄÇ\")\n",
        "    exit()\n",
        "except KeyError as e:\n",
        "    print(f\"Ëá¥ÂëΩÈåØË™§: Ê¨Ñ‰ΩçÂêçÁ®±ÈåØË™§„ÄÇË´ãÊ™¢Êü•ÊÇ®ÁöÑ CSV Ê™îÊ°à‰∏≠ÊòØÂê¶Áº∫Â∞ëÂøÖË¶ÅÊ¨Ñ‰Ωç„ÄÇÈåØË™§: {e}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"ÁôºÁîü‰∏ÄËà¨ÈåØË™§: {e}\")\n",
        "    exit()\n",
        "lyrics_dataset = Dataset.from_pandas(target_df.reset_index(drop=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_IRczZX_jQ5",
        "outputId": "dd7fd0c3-a62b-4570-c97f-b66d8732f659"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Êï∏ÊìöÊ∫ñÂÇôËàáÁØ©ÈÅ∏ (HOT 2010-2019) - ÊúÄÁµÇÂ≠óÂÖÉ‰øÆÊ≠£ ---\n",
            "‚úÖ ÁØ©ÈÅ∏Âá∫ 20 Á≠ÜÁõÆÊ®ôÊ≠åË©ûÊï∏Êìö„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÈÅ∏ÊìáÊúÄÁ©©ÂÆö„ÄÅÂÆòÊñπÊîØÊåÅÁöÑÈüìÊñáÁîüÊàêÊ®°Âûã\n",
        "model_id = \"skt/kogpt2-base-v2\"  # <-- ÊúÄÁµÇÂª∫Ë≠∞‰ΩøÁî®ÈÄôÂÄãÊ®ôÊ∫ñÊ®°Âûã\n",
        "\n",
        "try:\n",
        "    print(f\"ÂòóË©¶ËºâÂÖ•Ê®ôÊ∫ñ KoGPT2 Ê®°Âûã: {model_id}\")\n",
        "    # ‰ΩøÁî® Auto È°ûÂà•ÔºåÂõ†ÁÇ∫ÂÆòÊñπÊ®°ÂûãÈÖçÁΩÆÂÆåÊï¥\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
        "\n",
        "    # Ë®≠ÁΩÆ Tokenizer ÁöÑ Pad Token\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    print(\"‚úÖ Tokenizer ÂíåÊ®°ÂûãÂ∑≤ÊàêÂäüËºâÂÖ•„ÄÇ\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ËºâÂÖ• {model_id} ÊôÇÁôºÁîüÈåØË™§: {e}\")\n",
        "    print(\"Ë´ãÁ¢∫Ë™çÊÇ®ÁöÑ transformers Â∫´ÁâàÊú¨ÊòØÂê¶Ë∂≥Â§†Êñ∞„ÄÇ\")\n",
        "    exit()\n",
        "\n",
        "# ----------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4mp1nf6GehA",
        "outputId": "225037eb-eb56-47c3-fafe-a0105894d56d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÂòóË©¶ËºâÂÖ•Ê®ôÊ∫ñ KoGPT2 Ê®°Âûã: skt/kogpt2-base-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Tokenizer ÂíåÊ®°ÂûãÂ∑≤ÊàêÂäüËºâÂÖ•„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Ê≠•È©ü 3ÔºöÊ®°ÂûãËºâÂÖ•Ëàá Tokenizer ‰øÆÊ≠£ --------------------\n",
        "\n",
        "# Á¢∫‰øùÊâÄÊúâÂøÖË¶ÅÁöÑÂáΩÂºèÂ∫´Â∑≤ÂåØÂÖ•ÔºàÂÅáË®≠ÊÇ®Â∑≤Âú®Á®ãÂºèÈ†ÇÈÉ®ÂåØÂÖ•Ôºâ\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "import torch\n",
        "\n",
        "model_id = \"skt/kogpt2-base-v2\"  # Á©©ÂÆö‰∏îÂÆòÊñπÊîØÊåÅÁöÑ KoGPT2 Ê®°Âûã\n",
        "print(f\"\\n--- 3. Ê®°ÂûãËºâÂÖ•„ÄÅÂàÜË©ûËàáÂàáÂàÜ ---\")\n",
        "print(f\"ÂòóË©¶ËºâÂÖ•Ê®ôÊ∫ñ KoGPT2 Ê®°Âûã: {model_id}\")\n",
        "\n",
        "# ËºâÂÖ•Ê®°ÂûãÂíå Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
        "\n",
        "# üö® Tokenizer ‰øÆÊ≠£ÔºöÊòéÁ¢∫Ë®≠ÂÆö Padding ÂèÉÊï∏ÔºåËß£Ê±∫ÈÉ®ÂàÜ CUDA ÂïèÈ°å\n",
        "tokenizer.padding_side = \"right\"\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # üö® Padding ‰øÆÊ≠£ÔºöÂº∑Âà∂Â°´ÂÖÖÂà∞ÊúÄÂ§ßÈï∑Â∫¶ 128\n",
        "    return tokenizer(\n",
        "        examples[\"full_lyrics\"],\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding='max_length'\n",
        "    )\n",
        "\n",
        "print(\"Ê≠£Âú®ÈÄ≤Ë°åÂàÜË©ûÂíåÊï∏ÊìöÂàáÂàÜ...\")\n",
        "\n",
        "# ÈÄ≤Ë°å Tokenizer\n",
        "tokenized_datasets = lyrics_dataset.map(tokenize_function, batched=True, remove_columns=[\"full_lyrics\"])\n",
        "\n",
        "# Êò†Â∞ÑÊ®ôÁ±§ (Labels)\n",
        "lm_datasets = tokenized_datasets.map(\n",
        "    lambda x: {\"labels\": x[\"input_ids\"]},\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "# ÂäÉÂàÜË®ìÁ∑¥ÈõÜÂíåÊ∏¨Ë©¶ÈõÜ\n",
        "if len(lm_datasets) > 1:\n",
        "    train_test_split = lm_datasets.train_test_split(test_size=0.1)\n",
        "    train_dataset = train_test_split['train']\n",
        "    eval_dataset = train_test_split['test']\n",
        "    print(f\"‚úÖ Êï∏ÊìöÈõÜÂ∑≤ÊàêÂäüÂàáÂàÜÁÇ∫Ë®ìÁ∑¥ÈõÜ ({len(train_dataset)} Á≠Ü) ÂíåÈ©óË≠âÈõÜ ({len(eval_dataset)} Á≠Ü)„ÄÇ\")\n",
        "else:\n",
        "    # ÈÅøÂÖç NameErrorÔºåÂç≥‰ΩøÊï∏Êìö‰∏çË∂≥‰πüÂ∞áÂÖ∂Ë®≠ÁΩÆÁÇ∫ None\n",
        "    train_dataset = None\n",
        "    eval_dataset = None\n",
        "    print(\"‚ùå Êï∏ÊìöÈáè‰∏çË∂≥ÔºåË®ìÁ∑¥ÈõÜÂíåÈ©óË≠âÈõÜÊú™ÂÆöÁæ©„ÄÇ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "9b01e1cba098403fba8ce8048d7d2edc",
            "62f2cc22f0bc4b5eb65ccae6ae299c41",
            "95e1d65bf8994d07a0d55a2f5162e8d0",
            "81fff1dc45374810a420db9909999f13",
            "db3f351b963b44059506633b923ea260",
            "cff3448565604eb4b1bc25ed727a3732",
            "6c845788f2f146558cf1e2a38e25f325",
            "0e6348a5c5bb4872a5f52898b6d361b7",
            "18084b46ad8f450c8d4d69bd95b830f4",
            "f229c550c02f42fdb1c0220d786308b0",
            "93d29c24f97f452b9253a41acff29fbc",
            "707197cb7aff4ef0a1caddfca08b0f72",
            "3adba48c26524ea2b9696647ab725138",
            "df3440cb7a044865a3e34d8d9baed274",
            "96b225ac781344c890b9a44568d090e5",
            "059f7b1a589941ab9564b10be59a3f14",
            "3478529c85f44795a66e839d081f6d41",
            "89076e752a634187af20897452d37056",
            "77de6a7c6a23496e847e513da0e0562b",
            "00710ccab52a4153a3e39be39ed491d5",
            "5797afeb81ba47c1ac4d797202a0e8cb",
            "ef21aff02dec4e16a68beb39c759a1dd"
          ]
        },
        "id": "a-XkKuruJTB6",
        "outputId": "2be1f612-bc32-4952-e428-34e216aaa21a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Ê®°ÂûãËºâÂÖ•„ÄÅÂàÜË©ûËàáÂàáÂàÜ ---\n",
            "ÂòóË©¶ËºâÂÖ•Ê®ôÊ∫ñ KoGPT2 Ê®°Âûã: skt/kogpt2-base-v2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ê≠£Âú®ÈÄ≤Ë°åÂàÜË©ûÂíåÊï∏ÊìöÂàáÂàÜ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b01e1cba098403fba8ce8048d7d2edc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "707197cb7aff4ef0a1caddfca08b0f72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Êï∏ÊìöÈõÜÂ∑≤ÊàêÂäüÂàáÂàÜÁÇ∫Ë®ìÁ∑¥ÈõÜ (18 Á≠Ü) ÂíåÈ©óË≠âÈõÜ (2 Á≠Ü)„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 3.5 ÊúÄÁµÇÊï∏ÊìöÈ°ûÂûãÂº∑Âà∂ËΩâÊèõ ---\")\n",
        "\n",
        "if train_dataset is not None:\n",
        "    # üö® ÈóúÈçµ‰øÆÊ≠£ÔºöÂ∞áÊâÄÊúâÊï∏ÂÄºÊ¨Ñ‰ΩçÂº∑Âà∂ËΩâÊèõÁÇ∫ PyTorch Long È°ûÂûãÔºåËß£Ê±∫Â∫ïÂ±§ CUDA ÈåØË™§\n",
        "    train_dataset.set_format(\n",
        "        type='torch',\n",
        "        columns=['input_ids', 'attention_mask', 'labels'],\n",
        "        output_all_columns=True,\n",
        "        dtype=torch.long\n",
        "    )\n",
        "    print(\"‚úÖ Ë®ìÁ∑¥ÈõÜÊï∏ÊìöÈ°ûÂûãÂ∑≤Âº∑Âà∂ËΩâÊèõÁÇ∫ torch.long„ÄÇ\")\n",
        "\n",
        "if eval_dataset is not None:\n",
        "    eval_dataset.set_format(\n",
        "        type='torch',\n",
        "        columns=['input_ids', 'attention_mask', 'labels'],\n",
        "        output_all_columns=True,\n",
        "        dtype=torch.long\n",
        "    )\n",
        "    print(\"‚úÖ È©óË≠âÈõÜÊï∏ÊìöÈ°ûÂûãÂ∑≤Âº∑Âà∂ËΩâÊèõÁÇ∫ torch.long„ÄÇ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwRuRNymJUyc",
        "outputId": "d6d19983-7239-46ab-d619-194c0dd63fac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3.5 ÊúÄÁµÇÊï∏ÊìöÈ°ûÂûãÂº∑Âà∂ËΩâÊèõ ---\n",
            "‚úÖ Ë®ìÁ∑¥ÈõÜÊï∏ÊìöÈ°ûÂûãÂ∑≤Âº∑Âà∂ËΩâÊèõÁÇ∫ torch.long„ÄÇ\n",
            "‚úÖ È©óË≠âÈõÜÊï∏ÊìöÈ°ûÂûãÂ∑≤Âº∑Âà∂ËΩâÊèõÁÇ∫ torch.long„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if train_dataset is not None:\n",
        "    print(\"\\n--- 4. Ê®°ÂûãÂæÆË™ø (Fine-tuning) ÂïüÂãï ---\")\n",
        "\n",
        "    # 1. ÂÆöÁæ©Êï∏ÊìöÊâìÂåÖÂô® Data Collator\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False # Causal Language Modeling\n",
        "    )\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./snsd_lyrics_model\",\n",
        "        num_train_epochs=10,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        learning_rate=5e-5,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=100,\n",
        "\n",
        "        # üö® ÈóúÈçµ‰øÆÊ≠£ÔºöÁ¶ÅÁî®Ê∑∑ÂêàÁ≤æÂ∫¶Âíå wandb\n",
        "        fp16=False,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    print(\"üö® Ê≠£Âú®ÂïüÂãïÊ®°ÂûãË®ìÁ∑¥ (trainer.train())ÔºåË´ãÁ≠âÂæÖ... üö®\")\n",
        "    # ÂïüÂãïË®ìÁ∑¥ÔºÅ\n",
        "    trainer.train()\n",
        "\n",
        "    # Ë®ìÁ∑¥ÂÆåÊàêÂæåÂÑ≤Â≠òÊ®°Âûã\n",
        "    trainer.save_model(\"./snsd_lyrics_model_finetuned\")\n",
        "    print(\"\\n‚úÖ Ê®°ÂûãË®ìÁ∑¥ÂÆåÊàê‰∏¶Â∑≤ÂÑ≤Â≠òËá≥ './snsd_lyrics_model_finetuned' Ë≥áÊñôÂ§æ„ÄÇ\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Ë®ìÁ∑¥ÁÑ°Ê≥ïÈñãÂßãÔºöË®ìÁ∑¥Êï∏ÊìöÈõÜÁÇ∫Á©∫Êàñ‰∏çË∂≥„ÄÇË´ãÂõûÂà∞Ê≠•È©ü 2 ‰øÆÊ≠£Êï∏ÊìöÁØ©ÈÅ∏Ê¢ù‰ª∂„ÄÇ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "aQy-5jwmJZrg",
        "outputId": "55f656c7-18cd-409f-daf3-f338fd3268b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Ê®°ÂûãÂæÆË™ø (Fine-tuning) ÂïüÂãï ---\n",
            "üö® Ê≠£Âú®ÂïüÂãïÊ®°ÂûãË®ìÁ∑¥ (trainer.train())ÔºåË´ãÁ≠âÂæÖ... üö®\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:14, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Ê®°ÂûãË®ìÁ∑¥ÂÆåÊàê‰∏¶Â∑≤ÂÑ≤Â≠òËá≥ './snsd_lyrics_model_finetuned' Ë≥áÊñôÂ§æ„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# Ê≠•È©ü 5: ËºâÂÖ•ÂæÆË™øÂæåÁöÑÊ®°Âûã‰∏¶ÁîüÊàêÊ≠åË©û\n",
        "# =================================================================\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 1. Ë®≠ÂÆöË∑ØÂæëËàáË®≠ÂÇô\n",
        "fine_tuned_model_path = \"./snsd_lyrics_model_finetuned\"  # ÊÇ®ÂâõÂâõÂÑ≤Â≠òÊ®°ÂûãÁöÑË∑ØÂæë\n",
        "base_model_id = \"skt/kogpt2-base-v2\"                     # ÂéüÂßãÊ®°Âûã ID (Áî®ÊñºËºâÂÖ• Tokenizer)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Ê≠£Âú®ËºâÂÖ•ÂæÆË™øÂæåÁöÑÊ®°Âûã...\")\n",
        "try:\n",
        "    # ËºâÂÖ•ÊÇ®Ë®ìÁ∑¥Â•ΩÁöÑÊ®°ÂûãÊ¨äÈáç\n",
        "    model = AutoModelForCausalLM.from_pretrained(fine_tuned_model_path).to(device)\n",
        "    # ËºâÂÖ• Tokenizer (ÈÄöÂ∏∏‰ΩøÁî®ÂéüÂßãÂü∫Á§éÊ®°ÂûãÁöÑ Tokenizer Âç≥ÂèØ)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "    print(\"‚úÖ Ê®°ÂûãËºâÂÖ•ÊàêÂäüÔºÅ\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ËºâÂÖ•Â§±Êïó: {e}\")\n",
        "    print(\"Ë´ãÁ¢∫Ë™ç './snsd_lyrics_model_finetuned' Ë≥áÊñôÂ§æÊòØÂê¶Â≠òÂú®„ÄÇ\")\n",
        "    exit()\n",
        "\n",
        "# 2. ÂÆöÁæ©ÁîüÊàêÂáΩÂºè\n",
        "def generate_lyrics(prompt_text, max_length=150, temperature=0.7, top_k=50):\n",
        "    model.eval() # Ë®≠ÂÆöÁÇ∫Ë©ï‰º∞Ê®°Âºè\n",
        "\n",
        "    # Á∑®Á¢ºÊèêÁ§∫Ë©û\n",
        "    input_ids = tokenizer.encode(prompt_text, return_tensors='pt').to(device)\n",
        "\n",
        "    # ÁîüÊàê\n",
        "    with torch.no_grad():\n",
        "        output_sequences = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature, # ÂâµÊÑèÂ∫¶ÔºöË∂äÈ´òË∂äÈö®Ê©ü (0.7-1.0 ÈÅ©ÂêàÊ≠åË©û)\n",
        "            top_k=top_k,             # Êé°Ê®£Á≠ñÁï•\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.2,  # Èò≤Ê≠¢ÈáçË§áÊá≤ÁΩ∞\n",
        "            do_sample=True,          # ÂïüÁî®Èö®Ê©üÊé°Ê®£\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Ëß£Á¢ºÁîüÊàêÁöÑÊñáÂ≠ó\n",
        "    generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# =================================================================\n",
        "# 3. ÈñãÂßãÁîüÊàêÔºÅË©¶Ë©¶ÁúãËº∏ÂÖ•‰∏Ä‰∫õÂ∞ëÂ•≥ÊôÇ‰ª£È¢®Ê†ºÁöÑÈóúÈçµË©û\n",
        "# =================================================================\n",
        "\n",
        "# ÁØÑ‰æãÊèêÁ§∫Ë©û (ÊÇ®ÂèØ‰ª•Ëá™Áî±‰øÆÊîπ)\n",
        "prompts = [\n",
        "    \"Baby, I love you\",\n",
        "    \"I am so hot\",\n",
        "    'Ïù¥Ï†ú Î™®Îì† Í≤ÉÏùÑ'\n",
        "     # ÊäíÊÉÖÈ¢®Ê†º\n",
        "]\n",
        "\n",
        "print(f\"\\n--- üé∂HOT (2010-2019) È¢®Ê†ºÊ≠åË©ûÁîüÊàêÁµêÊûú üé∂ ---\\n\")\n",
        "\n",
        "for p in prompts:\n",
        "    print(f\"üîπ ÊèêÁ§∫Ë©û: {p}\")\n",
        "    lyrics = generate_lyrics(p, max_length=100)\n",
        "    print(f\"‚ú® ÁîüÊàêÊ≠åË©û:\\n{lyrics}\\n\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngNta_owLDu4",
        "outputId": "28a1eff7-dfc1-4062-d9e0-f158efc8aeb9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ê≠£Âú®ËºâÂÖ•ÂæÆË™øÂæåÁöÑÊ®°Âûã...\n",
            "‚úÖ Ê®°ÂûãËºâÂÖ•ÊàêÂäüÔºÅ\n",
            "\n",
            "--- üé∂HOT (2010-2019) È¢®Ê†ºÊ≠åË©ûÁîüÊàêÁµêÊûú üé∂ ---\n",
            "\n",
            "üîπ ÊèêÁ§∫Ë©û: Baby, I love you\n",
            "‚ú® ÁîüÊàêÊ≠åË©û:\n",
            "Baby, I love you gottain\n",
            "My movie, a fucking out!\n",
            "I can't know the needs to want into it's biggest for this handline.\n",
            "Here's so down only part of devices in Little House\n",
            "That's tell stop! It's everydays, and\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ ÊèêÁ§∫Ë©û: I am so hot\n",
            "‚ú® ÁîüÊàêÊ≠åË©û:\n",
            "I am so hot to me can't buy it know a little party, what did no, even's getsome into the factory\n",
            "Tip this satisfaction with your experience, twice from the stage\n",
            "And anything form of handlife, Him-shinton and John Gill\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ ÊèêÁ§∫Ë©û: Ïù¥Ï†ú Î™®Îì† Í≤ÉÏùÑ\n",
            "‚ú® ÁîüÊàêÊ≠åË©û:\n",
            "Ïù¥Ï†ú Î™®Îì† Í≤ÉÏùÑ Îã§ Ïûò Ìï† Ïàò ÏûàÍ∏∞Î•º Î∞îÎûÄÎã§.\n",
            "Í∑∏Îü∞Îç∞ ÎãπÏã†Îì§Ïùò ÏïûÎÇ†ÏùÄ Í≤∞ÏΩî Î∞ùÏßÄ ÏïäÎã§.\n",
            "Ïù¥Ï†ú Ï†ÄÎì§ÎèÑ Î™®ÎëêÎì§ Ïù¥ Í∏∏ÏùÑ Í∞ÄÎäî Í≤É ÏûêÏ≤¥Í∞Ä ÎëêÎ†§Ïö¥ ÏùºÏù¥Îã§.\n",
            "ÌïòÏßÄÎßå Ïö∞Î¶¨Îäî ÏßÄÍ∏à Î™®ÎëêÍ∞Ä ÎÇ¥ ÏïûÏóê ÎÜìÏó¨ ÏûàÎäî Ïù¥Îü¨Ìïú ÌòÑÏã§Ïóê ÎßûÏÑúÍ≥† ÏûàÎã§.\n",
            "Ïö∞Î¶¨Í∞Ä Ìï®Íªò ÌûòÏùÑ Î™®ÏïÑÏïº ÌïúÎã§.\n",
            "Ïö∞Î¶¨Îäî ÏÑúÎ°úÎ•º Ïù¥Ìï¥ÌïòÍ≥† Ïö©ÏÑúÌïòÎ©∞ Í∑∏ ÏÇ¨ÎûëÏùÑ Îã§Ïãú Ìïú Î≤à ÌôïÏù∏ÌïòÎäî Í≤ÉÏù¥ Ïö∞Î¶¨Ïùò ÏùòÎ¨¥Ïù¥Îã§.\n",
            "Ïö∞Î¶¨ÏóêÍ≤å Ï£ºÏñ¥ÏßÑ ÎßàÏßÄÎßâ ÎÇ®ÏùÄ ÏÑ†ÌÉù\n",
            "ÎÇòÏùò Îëê Î≤àÏß∏ ÏûÑÎ¨¥Í∞Ä Î∞îÎ°ú ÎÇòÏùò Ï°¥Ïû¨ Ïù¥Ïú†Ïùò ÌôïÏù∏Ïóê ÏûàÏäµÎãàÎã§.\n",
            "Îçî Ïù¥ÏÉÅ ÎÇò ÏûêÏã†ÏùÑ ÎØøÏßÄ ÎßêÏïÑÏ£º\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Ë®ìÁ∑¥Êï∏ÊìöÊäΩÊ®£Ê™¢Êü• ---\")\n",
        "sample_text = tokenizer.decode(train_dataset[0]['input_ids'], skip_special_tokens=True)\n",
        "print(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGAmgsV7L2uV",
        "outputId": "f37da396-3de3-4af8-92a1-095756858432"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ë®ìÁ∑¥Êï∏ÊìöÊäΩÊ®£Ê™¢Êü• ---\n",
            "Ïù¥Ï†ú Î™®Îì† Í≤ÉÏùÑ Îã§ Î™®ÎëêÍ∞Ä\n",
            "Í∏∞Îã§Î†§Ï£ºÏßÄ ÏïäÎäîÎã§Îäî Í≤ÉÏóê Ïù¥Îü∞ ÌòÑÏã§ ÏÜçÏóê(ÏÜçÏóê)\n",
            "ÏÉàÎ°≠Í≤å Î∞îÍøî Í∞ÄÏïºÌïòÎäî ÎÇòÏùò ÏùòÏßÄÏôÄ\n",
            "Í≤∞ÏΩî Ìè¨Í∏∞ÌïòÏßÄ ÏïäÎäîuh! Ïö∞Î¶¨Îì§Ïùò Íµ≥ÏùÄ Í≤∞Ïùò(Í≤∞Ïùò)\n",
            "Ïù¥Í≤ÉÏúºÎ°ú Îòê Î™®ÎëêÍ∞Ä ÏßÄÏºúÎÇ¥Ïïº Ìï†(ÎÇ¥Í∞Ä Ìï†)\n",
            "Ïö∞Î¶¨Îì§Ïùò ÎØ∏Îûò life concept tic toc to the OP.T\n",
            "ÎÇ¥Í≤å Í∏∞Îã§Î¶∞ ÎÇ¥Í≤å Ïù¥Ï†úÏôÄ ÏÇ¥ÏïÑÍ∞à Ïàò ÏûàÍ≤å\n",
            "ÌïúÏóÜÏù¥ ÌïèÎπõÏóê Î¨ºÎì§ Í≤ÉÏùÄ Ïù¥Ï†ú ÏóÜÍ≤å\n",
            "Ïö∞Î¶¨Í∞Ä ÎèåÏïÑÍ∞à Ïàò ÏûàÎäî Í∏∏ÏùÄ ÏóÜÎã§\n",
            "Ïò§ÏßÅ ÏïûÎßåÏùÑ Ìñ•Ìï¥\n",
            "Í∫ºÏ†∏ Í∞ÄÎäî Î™®Îì† Í≤ÉÏùÑ Ïù¥Ï†ú ÎÇ¥Í∞Ä Îπ†ÏßêÏóÜÏù¥ ÎπÑÏ∂∞Ï£ºÎ¶¨Îùº\n",
            "Ïñ∏Ï†úÎÇò Í∏∞Îã§Î†§ÏôîÏñ¥ ÎÑà ÏóÜÎäî\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# ÁÑ°Ê¢ù‰ª∂ÁîüÊàê (Unconditional Generation)\n",
        "# =================================================================\n",
        "\n",
        "import torch\n",
        "\n",
        "# 1. Ê∫ñÂÇô„ÄåÈñãÂßã‰ø°Ëôü„Äç\n",
        "# Â§ßÂ§öÊï∏Ê®°ÂûãÈÉΩÊúâ‰∏ÄÂÄãÁâπÊÆäÁöÑ \"BOS\" (Beginning of Sentence) token\n",
        "# Â¶ÇÊûúÊ®°ÂûãÊ≤íÊúâË®≠ÂÆö BOSÔºåÊàëÂÄëÂ∞±Áî® EOS (End of Sentence) ‰ª£ÊõøÔºåÊïàÊûúÈÄöÂ∏∏‰∏ÄÊ®£\n",
        "start_token = tokenizer.bos_token_id if tokenizer.bos_token_id is not None else tokenizer.eos_token_id\n",
        "\n",
        "# Âª∫Á´ãÂè™Êúâ‰∏ÄÂÄãÈñãÂßãÁ¨¶ËôüÁöÑËº∏ÂÖ•\n",
        "input_ids = torch.tensor([[start_token]], device=device)\n",
        "\n",
        "# 2. ÁîüÊàêË®≠ÂÆö\n",
        "print(\"üé∂ Ê≠£Âú®Èö®Ê©üÂâµ‰ΩúHOTÈ¢®Ê†ºÊ≠åË©û (ÁÑ°ÊèêÁ§∫Ë©û)... üé∂\\n\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=200,          # Ë®≠ÂÆöÈï∑‰∏ÄÈªûÔºåËÆìÂÆÉÂØ´ÂÆå‰∏ÄÊÆµ\n",
        "        temperature=0.8,         # Á®çÂæÆÈ´ò‰∏ÄÈªûÁöÑÂâµÊÑèÂ∫¶\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2,  # Èò≤Ê≠¢È¨ºÊâìÁâÜ\n",
        "        do_sample=True,          # Èö®Ê©üÊé°Ê®£\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "# 3. Ëß£Á¢ºÁµêÊûú\n",
        "generated_lyrics = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_lyrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUAio4BCOyFk",
        "outputId": "79439877-f9bd-4f67-9be9-53f6d0a491af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé∂ Ê≠£Âú®Èö®Ê©üÂâµ‰ΩúHOTÈ¢®Ê†ºÊ≠åË©û (ÁÑ°ÊèêÁ§∫Ë©û)... üé∂\n",
            "\n",
            "\n",
            "\n",
            "#blacknow .\n",
            "#singapore #movie #instagood #instafashion Ïò§ÎäòÏùÄ ÏôúÏù¥Î†áÍ≤å ÎßõÎÇúÍ±∞Ïïº~\n",
            "ÏïÑÏπ®Î∂ÄÌÑ∞ Ïù¥ÏÅòÎã§ ÏÉùÍ∞ÅÌïòÏÖîÏÑú ÏñºÎ•∏ Î®πÍ∏∞Î°ú ÌñàÏñ¥Ïöî\n",
            "Í∑∏ÎûòÎèÑ ÏïÑÍπåÏõåÏÑú Î™ªÎ®πÍ≤†Ïñ¥ÏÑú Îçî ÏïàÎ®πÏóàÎçîÎãà Ïù¥Î†áÍ≤å ÎßõÏûàÎäîÍ≤å Îòê Ïñ¥ÎîîÏûàÏñ¥Ïöî!\n",
            "ÏñºÎßàÎÇò Î®πÍ≥†Ïã∂ÏóàÎäîÎç∞ ÎÑàÎ¨¥ Î∞∞Í∞Ä Î∂àÎ†ÄÎäîÏßÄ\n",
            "ÏÉàÎ≤ΩÍπåÏßÄ Í≥†ÏÉùÏù¥ ÎßéÏúºÏãúÎçò Ìï†Î®∏ÎãàÏôÄ\n",
            "Ï†ÄÎÖÅÍπåÏßÄ Î∞ñÏóêÏÑú Íº¨Î∞ïÍº¨Î∞ï Íº¨Î∞ï Ï±ôÍ≤®Ï£ºÏãúÎäî Ïò§Îπ†. Ï†ïÎßê Í∞êÏÇ¨Ìï©ÎãàÎãπ ·Ñí·Ñí\n",
            "Ïò§ÎäòÏùÄ Íº≠Íº≠ Î®πÏñ¥ÏïºÌï† Í≤É Í∞ôÏùÄÎç∞Ïö©! Ïö∞Î¶¨ Í∞ÄÏ°±Îì§Ïù¥Îûë Ïò§Ïã§ Ïàò ÏûàÎäî Î©îÎâ¥Í∞Ä ÏûàÏñ¥ÏÑú\n",
            "ÌïúÎ≤àÏØ§ ÌïúÎ≤àÏóê Î®πÏñ¥Î≥º ÎßåÌïú ÏùåÏãùÏù¥ÏóêÏöî \n",
            "Î©îÏù∏ÏúºÎ°úÎäî ÎëêÎ∂ÄÍµ¨Ïù¥ / ÏΩ©ÎÇòÎ¨ºÎ¨¥Ïπ®, Î≤ÑÏÑØÏÉêÎü¨Îìú, Í∑∏Î¶¨Í≥† Í≥†Ï∂îÏû•Ï∞åÍ∞ú, Îã≠Í∞ÄÏä¥ÏÇ¥Î≥∂ÏùåÎ∞• / ÏÉêÎü¨ÎìúÎ∞î\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ê™¢Êü•ÊÇ®ÁöÑÊï∏ÊìöÈõÜÂÖßÂÆπ\n",
        "print(\"--- üîç Êï∏ÊìöÈõÜÂÖßÂÆπÊ™¢Êü• ---\")\n",
        "\n",
        "# Èö®Ê©üÊü•Áúã 3 Á≠ÜË®ìÁ∑¥Êï∏ÊìöÁöÑÂéüÂßãÊñáÊú¨\n",
        "import random\n",
        "for i in range(3):\n",
        "    try:\n",
        "        # ÊàëÂÄëÂ∞á input_ids ËΩâÂõûÊñáÂ≠óÔºåÁúãÁúãÊ®°ÂûãÂØ¶ÈöõÂ≠∏Âà∞‰∫Ü‰ªÄÈ∫º\n",
        "        sample_id = random.randint(0, len(train_dataset) - 1)\n",
        "        decoded_text = tokenizer.decode(train_dataset[sample_id]['input_ids'], skip_special_tokens=True)\n",
        "        print(f\"\\nüìÑ Ê®£Êú¨ {i+1}:\")\n",
        "        print(decoded_text[:200] + \"...\") # Âè™Âç∞Ââç200Â≠ó\n",
        "    except Exception as e:\n",
        "        print(f\"ËÆÄÂèñÂ§±Êïó: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDQ3NeezPmp-",
        "outputId": "e0cdeea3-3c51-46cd-a34a-820089722d89"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- üîç Êï∏ÊìöÈõÜÂÖßÂÆπÊ™¢Êü• ---\n",
            "\n",
            "üìÑ Ê®£Êú¨ 1:\n",
            "ÎØ∏ÏïàÌï¥ ÎÑ§Í≤å ÏÉÅÏ≤ò Ï§¨Îçò Í≤É Ï∞©ÌïòÍ∏∞Îßå ÌïòÎçò\n",
            "ÎÑàÏùò ÌïòÏñÄ Îëê Î≥º ÏúÑÏóêÏÑú ÎààÎ¨º ÌùòÎ¶¨Í≤å Ìïú Í≤É\n",
            "Ïö©ÏÑúÌï¥ Ïö©ÏÑúÌï¥ÏïºÎßå Ìï¥Ïöî Í∑∏ÎåÄ Îñ†ÎÇòÍ∞ÄÎäî Í≤å\n",
            "ÎÇòÎäî ÎÑàÎ¨¥ ÎëêÎ†§Ïõ†Í∏∞Ïóê ÎÑàÎ¨¥ ÏÇ¨ÎûëÌñàÍ∏∞Ïóê\n",
            "ÌïúÎïê Í∑∏ÎåÄÍ∞Ä ÎÇ¥ Í≥ÅÏóê ÏóÜÎäî Í≤å\n",
            "ÎÑàÎ¨¥ÎÇò ÌûòÏù¥ Îì§Í≥† Îòê Ïô∏Î°úÏõåÏÑú\n",
            "ÎπÑÍ∞Ä ÎÇ¥Î¶¨Îçò ÎÇ† ÎÇú ÎπÑÎ•º ÎßûÏúºÎ©∞\n",
            "ÌïúÏóÜÏù¥ Ïö∏ÏóàÏóàÏ£†\n",
            "Í∑∏ÎåÄÎ•º ÏÇ¨ÎûëÌï¥Ïöî Î≥¥Í≥† Ïã∂Ïñ¥Ïöî\n",
            "Í∑∏Îåà ÎßåÎÇò ÌñâÎ≥µÌñàÎçò Í≤ÉÎßåÌÅº\n",
            "ÎÇ¥Í∞Ä ÏïΩÏÜçÌï†Í≤åÏöî Ïù¥Ï†ú Îã§ÏãúÎäî\n",
            "...\n",
            "\n",
            "üìÑ Ê®£Êú¨ 2:\n",
            "Ïù¥Ï†ú Î™®Îì† Í≤ÉÏùÑ Îã§ Î™®ÎëêÍ∞Ä\n",
            "Í∏∞Îã§Î†§Ï£ºÏßÄ ÏïäÎäîÎã§Îäî Í≤ÉÏóê Ïù¥Îü∞ ÌòÑÏã§ ÏÜçÏóê(ÏÜçÏóê)\n",
            "ÏÉàÎ°≠Í≤å Î∞îÍøî Í∞ÄÏïºÌïòÎäî ÎÇòÏùò ÏùòÏßÄÏôÄ\n",
            "Í≤∞ÏΩî Ìè¨Í∏∞ÌïòÏßÄ ÏïäÎäîuh! Ïö∞Î¶¨Îì§Ïùò Íµ≥ÏùÄ Í≤∞Ïùò(Í≤∞Ïùò)\n",
            "Ïù¥Í≤ÉÏúºÎ°ú Îòê Î™®ÎëêÍ∞Ä ÏßÄÏºúÎÇ¥Ïïº Ìï†(ÎÇ¥Í∞Ä Ìï†)\n",
            "Ïö∞Î¶¨Îì§Ïùò ÎØ∏Îûò life concept tic toc to the OP.T\n",
            "ÎÇ¥Í≤å Í∏∞Îã§Î¶∞ ÎÇ¥Í≤å Ïù¥Ï†úÏôÄ ÏÇ¥ÏïÑÍ∞à Ïàò ÏûàÍ≤å\n",
            "ÌïúÏóÜÏù¥ ÌïèÎπõÏóê Î¨ºÎì§ Í≤ÉÏùÄ Ïù¥Ï†ú ÏóÜÍ≤å\n",
            "Ïö∞Î¶¨...\n",
            "\n",
            "üìÑ Ê®£Êú¨ 3:\n",
            "Pump up the track some for your partner\n",
            "\n",
            "Lets see how many rappers can go the length\n",
            "Back in your system with extra strength\n",
            "We eat emcees, outdo and surpass em\n",
            "But what's gonna make ya different than...\n"
          ]
        }
      ]
    }
  ]
}